{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day077_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhwYXx-vrnYM",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
        "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ONeOsjPrnYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "af2043d6-af31-44f3-fb2a-3f0fb3f5a097"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b8_cou9rnYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03196201-eb88-4fb3-a24c-e999675fbc9b"
      },
      "source": [
        "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqsD2Bg9rnYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將 X 與 Y 獨立放進變數\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "# 資料前處理 - 標準化\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "x_test = x_test.reshape((len(x_test), -1))\n",
        "\n",
        "# 將目標轉為 one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AomeFxNbrnYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3a8c6771-a358-4549-8804-b4b8bb6b50bb"
      },
      "source": [
        "def build_mlp():\n",
        "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
        "    x = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
        "    x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(units=128, activation=\"relu\")(x)\n",
        "    out = keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    return model\n",
        "model = build_mlp()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcadF80mrnYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "afd7904e-e269-4cb9-c9c1-b7b0d9ba7677"
      },
      "source": [
        "\"\"\"\n",
        "Compile 模型\n",
        "\"\"\"\n",
        "model = build_mlp()\n",
        "# 用 Keras 內建方法檢視模型各層參數量\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dY6OOfDwrnYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56bf96cd-668b-47a5-96ff-57f8cfc2e3fe"
      },
      "source": [
        "\"\"\"\n",
        "設定要訓練的 Epoch 數\n",
        "\"\"\"\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=500, \n",
        "          batch_size=256, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.2860 - acc: 0.1415 - val_loss: 2.2329 - val_acc: 0.1831\n",
            "Epoch 2/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 2.2048 - acc: 0.2032 - val_loss: 2.1766 - val_acc: 0.2218\n",
            "Epoch 3/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 2.1539 - acc: 0.2279 - val_loss: 2.1298 - val_acc: 0.2390\n",
            "Epoch 4/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 2.1099 - acc: 0.2429 - val_loss: 2.0887 - val_acc: 0.2536\n",
            "Epoch 5/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 2.0723 - acc: 0.2575 - val_loss: 2.0552 - val_acc: 0.2669\n",
            "Epoch 6/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 2.0408 - acc: 0.2730 - val_loss: 2.0256 - val_acc: 0.2802\n",
            "Epoch 7/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 2.0129 - acc: 0.2853 - val_loss: 2.0005 - val_acc: 0.2889\n",
            "Epoch 8/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.9887 - acc: 0.2950 - val_loss: 1.9780 - val_acc: 0.2970\n",
            "Epoch 9/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.9672 - acc: 0.3034 - val_loss: 1.9584 - val_acc: 0.3147\n",
            "Epoch 10/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.9482 - acc: 0.3127 - val_loss: 1.9413 - val_acc: 0.3153\n",
            "Epoch 11/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.9309 - acc: 0.3201 - val_loss: 1.9242 - val_acc: 0.3267\n",
            "Epoch 12/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.9149 - acc: 0.3267 - val_loss: 1.9092 - val_acc: 0.3342\n",
            "Epoch 13/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.9010 - acc: 0.3343 - val_loss: 1.8963 - val_acc: 0.3367\n",
            "Epoch 14/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.8886 - acc: 0.3376 - val_loss: 1.8855 - val_acc: 0.3438\n",
            "Epoch 15/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.8778 - acc: 0.3429 - val_loss: 1.8759 - val_acc: 0.3427\n",
            "Epoch 16/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.8676 - acc: 0.3459 - val_loss: 1.8665 - val_acc: 0.3483\n",
            "Epoch 17/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.8588 - acc: 0.3495 - val_loss: 1.8570 - val_acc: 0.3514\n",
            "Epoch 18/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.8503 - acc: 0.3525 - val_loss: 1.8493 - val_acc: 0.3545\n",
            "Epoch 19/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.8428 - acc: 0.3543 - val_loss: 1.8413 - val_acc: 0.3560\n",
            "Epoch 20/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.8354 - acc: 0.3576 - val_loss: 1.8341 - val_acc: 0.3589\n",
            "Epoch 21/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.8284 - acc: 0.3609 - val_loss: 1.8282 - val_acc: 0.3628\n",
            "Epoch 22/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.8218 - acc: 0.3634 - val_loss: 1.8220 - val_acc: 0.3629\n",
            "Epoch 23/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.8156 - acc: 0.3654 - val_loss: 1.8149 - val_acc: 0.3653\n",
            "Epoch 24/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.8094 - acc: 0.3665 - val_loss: 1.8100 - val_acc: 0.3738\n",
            "Epoch 25/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.8034 - acc: 0.3690 - val_loss: 1.8030 - val_acc: 0.3698\n",
            "Epoch 26/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.7979 - acc: 0.3719 - val_loss: 1.7976 - val_acc: 0.3763\n",
            "Epoch 27/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.7919 - acc: 0.3740 - val_loss: 1.7960 - val_acc: 0.3738\n",
            "Epoch 28/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.7867 - acc: 0.3758 - val_loss: 1.7874 - val_acc: 0.3784\n",
            "Epoch 29/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.7813 - acc: 0.3767 - val_loss: 1.7807 - val_acc: 0.3782\n",
            "Epoch 30/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.7761 - acc: 0.3797 - val_loss: 1.7761 - val_acc: 0.3827\n",
            "Epoch 31/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.7710 - acc: 0.3806 - val_loss: 1.7720 - val_acc: 0.3810\n",
            "Epoch 32/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.7658 - acc: 0.3843 - val_loss: 1.7670 - val_acc: 0.3871\n",
            "Epoch 33/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.7613 - acc: 0.3853 - val_loss: 1.7627 - val_acc: 0.3871\n",
            "Epoch 34/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.7566 - acc: 0.3878 - val_loss: 1.7567 - val_acc: 0.3893\n",
            "Epoch 35/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.7516 - acc: 0.3884 - val_loss: 1.7529 - val_acc: 0.3924\n",
            "Epoch 36/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.7474 - acc: 0.3911 - val_loss: 1.7474 - val_acc: 0.3934\n",
            "Epoch 37/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.7429 - acc: 0.3926 - val_loss: 1.7439 - val_acc: 0.3993\n",
            "Epoch 38/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.7385 - acc: 0.3949 - val_loss: 1.7395 - val_acc: 0.3966\n",
            "Epoch 39/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.7344 - acc: 0.3960 - val_loss: 1.7350 - val_acc: 0.3988\n",
            "Epoch 40/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.7301 - acc: 0.3975 - val_loss: 1.7333 - val_acc: 0.3969\n",
            "Epoch 41/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.7263 - acc: 0.3986 - val_loss: 1.7277 - val_acc: 0.4023\n",
            "Epoch 42/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.7222 - acc: 0.4010 - val_loss: 1.7238 - val_acc: 0.4033\n",
            "Epoch 43/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.7184 - acc: 0.4003 - val_loss: 1.7195 - val_acc: 0.4048\n",
            "Epoch 44/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.7145 - acc: 0.4037 - val_loss: 1.7164 - val_acc: 0.4054\n",
            "Epoch 45/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.7107 - acc: 0.4040 - val_loss: 1.7130 - val_acc: 0.4073\n",
            "Epoch 46/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.7069 - acc: 0.4065 - val_loss: 1.7097 - val_acc: 0.4082\n",
            "Epoch 47/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.7033 - acc: 0.4072 - val_loss: 1.7048 - val_acc: 0.4116\n",
            "Epoch 48/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.6996 - acc: 0.4076 - val_loss: 1.7020 - val_acc: 0.4097\n",
            "Epoch 49/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.6961 - acc: 0.4098 - val_loss: 1.6987 - val_acc: 0.4112\n",
            "Epoch 50/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.6929 - acc: 0.4106 - val_loss: 1.6954 - val_acc: 0.4101\n",
            "Epoch 51/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.6893 - acc: 0.4122 - val_loss: 1.6926 - val_acc: 0.4131\n",
            "Epoch 52/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.6859 - acc: 0.4124 - val_loss: 1.6878 - val_acc: 0.4173\n",
            "Epoch 53/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.6824 - acc: 0.4149 - val_loss: 1.6847 - val_acc: 0.4155\n",
            "Epoch 54/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.6793 - acc: 0.4164 - val_loss: 1.6824 - val_acc: 0.4187\n",
            "Epoch 55/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.6757 - acc: 0.4173 - val_loss: 1.6789 - val_acc: 0.4203\n",
            "Epoch 56/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6726 - acc: 0.4181 - val_loss: 1.6765 - val_acc: 0.4209\n",
            "Epoch 57/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.6695 - acc: 0.4197 - val_loss: 1.6762 - val_acc: 0.4173\n",
            "Epoch 58/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.6663 - acc: 0.4208 - val_loss: 1.6693 - val_acc: 0.4210\n",
            "Epoch 59/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6632 - acc: 0.4210 - val_loss: 1.6686 - val_acc: 0.4199\n",
            "Epoch 60/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.6602 - acc: 0.4234 - val_loss: 1.6644 - val_acc: 0.4229\n",
            "Epoch 61/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6570 - acc: 0.4244 - val_loss: 1.6598 - val_acc: 0.4254\n",
            "Epoch 62/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.6539 - acc: 0.4252 - val_loss: 1.6609 - val_acc: 0.4264\n",
            "Epoch 63/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.6507 - acc: 0.4251 - val_loss: 1.6558 - val_acc: 0.4265\n",
            "Epoch 64/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6480 - acc: 0.4271 - val_loss: 1.6522 - val_acc: 0.4276\n",
            "Epoch 65/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.6450 - acc: 0.4274 - val_loss: 1.6484 - val_acc: 0.4282\n",
            "Epoch 66/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6421 - acc: 0.4282 - val_loss: 1.6470 - val_acc: 0.4322\n",
            "Epoch 67/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.6395 - acc: 0.4300 - val_loss: 1.6450 - val_acc: 0.4306\n",
            "Epoch 68/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6364 - acc: 0.4310 - val_loss: 1.6419 - val_acc: 0.4330\n",
            "Epoch 69/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.6337 - acc: 0.4326 - val_loss: 1.6389 - val_acc: 0.4290\n",
            "Epoch 70/500\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 1.6310 - acc: 0.4333 - val_loss: 1.6362 - val_acc: 0.4300\n",
            "Epoch 71/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.6278 - acc: 0.4340 - val_loss: 1.6350 - val_acc: 0.4324\n",
            "Epoch 72/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.6251 - acc: 0.4348 - val_loss: 1.6318 - val_acc: 0.4351\n",
            "Epoch 73/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6226 - acc: 0.4349 - val_loss: 1.6286 - val_acc: 0.4354\n",
            "Epoch 74/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.6197 - acc: 0.4362 - val_loss: 1.6253 - val_acc: 0.4349\n",
            "Epoch 75/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6170 - acc: 0.4377 - val_loss: 1.6226 - val_acc: 0.4362\n",
            "Epoch 76/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.6145 - acc: 0.4388 - val_loss: 1.6221 - val_acc: 0.4357\n",
            "Epoch 77/500\n",
            "50000/50000 [==============================] - 10s 200us/step - loss: 1.6119 - acc: 0.4392 - val_loss: 1.6191 - val_acc: 0.4375\n",
            "Epoch 78/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.6093 - acc: 0.4399 - val_loss: 1.6173 - val_acc: 0.4381\n",
            "Epoch 79/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.6065 - acc: 0.4420 - val_loss: 1.6140 - val_acc: 0.4391\n",
            "Epoch 80/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.6040 - acc: 0.4422 - val_loss: 1.6129 - val_acc: 0.4405\n",
            "Epoch 81/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.6017 - acc: 0.4432 - val_loss: 1.6090 - val_acc: 0.4417\n",
            "Epoch 82/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.5992 - acc: 0.4444 - val_loss: 1.6112 - val_acc: 0.4398\n",
            "Epoch 83/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.5963 - acc: 0.4455 - val_loss: 1.6056 - val_acc: 0.4402\n",
            "Epoch 84/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.5942 - acc: 0.4455 - val_loss: 1.6033 - val_acc: 0.4431\n",
            "Epoch 85/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.5917 - acc: 0.4476 - val_loss: 1.5997 - val_acc: 0.4428\n",
            "Epoch 86/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.5894 - acc: 0.4484 - val_loss: 1.5999 - val_acc: 0.4435\n",
            "Epoch 87/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.5873 - acc: 0.4484 - val_loss: 1.5964 - val_acc: 0.4456\n",
            "Epoch 88/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.5846 - acc: 0.4483 - val_loss: 1.5969 - val_acc: 0.4428\n",
            "Epoch 89/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.5823 - acc: 0.4498 - val_loss: 1.5934 - val_acc: 0.4422\n",
            "Epoch 90/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.5799 - acc: 0.4506 - val_loss: 1.5903 - val_acc: 0.4456\n",
            "Epoch 91/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.5776 - acc: 0.4518 - val_loss: 1.5891 - val_acc: 0.4465\n",
            "Epoch 92/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.5752 - acc: 0.4522 - val_loss: 1.5880 - val_acc: 0.4480\n",
            "Epoch 93/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.5733 - acc: 0.4532 - val_loss: 1.5909 - val_acc: 0.4497\n",
            "Epoch 94/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.5710 - acc: 0.4536 - val_loss: 1.5832 - val_acc: 0.4475\n",
            "Epoch 95/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.5688 - acc: 0.4543 - val_loss: 1.5818 - val_acc: 0.4485\n",
            "Epoch 96/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.5663 - acc: 0.4552 - val_loss: 1.5864 - val_acc: 0.4463\n",
            "Epoch 97/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.5645 - acc: 0.4561 - val_loss: 1.5796 - val_acc: 0.4487\n",
            "Epoch 98/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.5624 - acc: 0.4564 - val_loss: 1.5747 - val_acc: 0.4510\n",
            "Epoch 99/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.5600 - acc: 0.4576 - val_loss: 1.5732 - val_acc: 0.4525\n",
            "Epoch 100/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.5579 - acc: 0.4573 - val_loss: 1.5711 - val_acc: 0.4503\n",
            "Epoch 101/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.5555 - acc: 0.4592 - val_loss: 1.5727 - val_acc: 0.4534\n",
            "Epoch 102/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.5534 - acc: 0.4591 - val_loss: 1.5701 - val_acc: 0.4514\n",
            "Epoch 103/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.5514 - acc: 0.4600 - val_loss: 1.5720 - val_acc: 0.4484\n",
            "Epoch 104/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.5496 - acc: 0.4615 - val_loss: 1.5644 - val_acc: 0.4532\n",
            "Epoch 105/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.5475 - acc: 0.4616 - val_loss: 1.5627 - val_acc: 0.4543\n",
            "Epoch 106/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.5456 - acc: 0.4612 - val_loss: 1.5629 - val_acc: 0.4556\n",
            "Epoch 107/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.5433 - acc: 0.4630 - val_loss: 1.5588 - val_acc: 0.4549\n",
            "Epoch 108/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.5415 - acc: 0.4639 - val_loss: 1.5583 - val_acc: 0.4548\n",
            "Epoch 109/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.5392 - acc: 0.4641 - val_loss: 1.5588 - val_acc: 0.4523\n",
            "Epoch 110/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.5375 - acc: 0.4647 - val_loss: 1.5567 - val_acc: 0.4548\n",
            "Epoch 111/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.5354 - acc: 0.4657 - val_loss: 1.5533 - val_acc: 0.4558\n",
            "Epoch 112/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.5336 - acc: 0.4654 - val_loss: 1.5508 - val_acc: 0.4595\n",
            "Epoch 113/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.5316 - acc: 0.4669 - val_loss: 1.5513 - val_acc: 0.4553\n",
            "Epoch 114/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.5297 - acc: 0.4670 - val_loss: 1.5498 - val_acc: 0.4580\n",
            "Epoch 115/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.5279 - acc: 0.4675 - val_loss: 1.5465 - val_acc: 0.4594\n",
            "Epoch 116/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.5254 - acc: 0.4685 - val_loss: 1.5471 - val_acc: 0.4605\n",
            "Epoch 117/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.5239 - acc: 0.4693 - val_loss: 1.5459 - val_acc: 0.4575\n",
            "Epoch 118/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.5220 - acc: 0.4702 - val_loss: 1.5441 - val_acc: 0.4588\n",
            "Epoch 119/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.5199 - acc: 0.4700 - val_loss: 1.5426 - val_acc: 0.4614\n",
            "Epoch 120/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.5181 - acc: 0.4715 - val_loss: 1.5454 - val_acc: 0.4588\n",
            "Epoch 121/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.5162 - acc: 0.4718 - val_loss: 1.5397 - val_acc: 0.4617\n",
            "Epoch 122/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.5150 - acc: 0.4727 - val_loss: 1.5366 - val_acc: 0.4634\n",
            "Epoch 123/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.5126 - acc: 0.4729 - val_loss: 1.5370 - val_acc: 0.4640\n",
            "Epoch 124/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.5111 - acc: 0.4742 - val_loss: 1.5366 - val_acc: 0.4611\n",
            "Epoch 125/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.5091 - acc: 0.4739 - val_loss: 1.5326 - val_acc: 0.4616\n",
            "Epoch 126/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.5078 - acc: 0.4747 - val_loss: 1.5337 - val_acc: 0.4620\n",
            "Epoch 127/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.5058 - acc: 0.4762 - val_loss: 1.5288 - val_acc: 0.4626\n",
            "Epoch 128/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.5038 - acc: 0.4758 - val_loss: 1.5301 - val_acc: 0.4615\n",
            "Epoch 129/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.5025 - acc: 0.4760 - val_loss: 1.5295 - val_acc: 0.4620\n",
            "Epoch 130/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.5004 - acc: 0.4772 - val_loss: 1.5260 - val_acc: 0.4659\n",
            "Epoch 131/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.4988 - acc: 0.4775 - val_loss: 1.5293 - val_acc: 0.4644\n",
            "Epoch 132/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.4967 - acc: 0.4785 - val_loss: 1.5257 - val_acc: 0.4645\n",
            "Epoch 133/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.4954 - acc: 0.4796 - val_loss: 1.5234 - val_acc: 0.4662\n",
            "Epoch 134/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4933 - acc: 0.4790 - val_loss: 1.5237 - val_acc: 0.4662\n",
            "Epoch 135/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.4922 - acc: 0.4798 - val_loss: 1.5192 - val_acc: 0.4668\n",
            "Epoch 136/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.4902 - acc: 0.4809 - val_loss: 1.5169 - val_acc: 0.4666\n",
            "Epoch 137/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.4883 - acc: 0.4805 - val_loss: 1.5179 - val_acc: 0.4688\n",
            "Epoch 138/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4868 - acc: 0.4819 - val_loss: 1.5167 - val_acc: 0.4702\n",
            "Epoch 139/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.4853 - acc: 0.4824 - val_loss: 1.5158 - val_acc: 0.4699\n",
            "Epoch 140/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.4833 - acc: 0.4844 - val_loss: 1.5192 - val_acc: 0.4693\n",
            "Epoch 141/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.4820 - acc: 0.4830 - val_loss: 1.5165 - val_acc: 0.4702\n",
            "Epoch 142/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.4798 - acc: 0.4836 - val_loss: 1.5112 - val_acc: 0.4722\n",
            "Epoch 143/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.4787 - acc: 0.4845 - val_loss: 1.5090 - val_acc: 0.4732\n",
            "Epoch 144/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.4769 - acc: 0.4855 - val_loss: 1.5073 - val_acc: 0.4722\n",
            "Epoch 145/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4752 - acc: 0.4868 - val_loss: 1.5080 - val_acc: 0.4714\n",
            "Epoch 146/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.4743 - acc: 0.4859 - val_loss: 1.5053 - val_acc: 0.4721\n",
            "Epoch 147/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.4719 - acc: 0.4873 - val_loss: 1.5064 - val_acc: 0.4716\n",
            "Epoch 148/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4707 - acc: 0.4883 - val_loss: 1.5030 - val_acc: 0.4755\n",
            "Epoch 149/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4688 - acc: 0.4883 - val_loss: 1.5065 - val_acc: 0.4688\n",
            "Epoch 150/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4676 - acc: 0.4886 - val_loss: 1.5020 - val_acc: 0.4752\n",
            "Epoch 151/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.4659 - acc: 0.4901 - val_loss: 1.5043 - val_acc: 0.4749\n",
            "Epoch 152/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.4640 - acc: 0.4899 - val_loss: 1.5083 - val_acc: 0.4715\n",
            "Epoch 153/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.4631 - acc: 0.4905 - val_loss: 1.4960 - val_acc: 0.4779\n",
            "Epoch 154/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4608 - acc: 0.4909 - val_loss: 1.5038 - val_acc: 0.4717\n",
            "Epoch 155/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.4594 - acc: 0.4918 - val_loss: 1.4971 - val_acc: 0.4753\n",
            "Epoch 156/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.4580 - acc: 0.4923 - val_loss: 1.4928 - val_acc: 0.4773\n",
            "Epoch 157/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.4563 - acc: 0.4923 - val_loss: 1.4953 - val_acc: 0.4782\n",
            "Epoch 158/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4550 - acc: 0.4938 - val_loss: 1.4924 - val_acc: 0.4774\n",
            "Epoch 159/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4532 - acc: 0.4929 - val_loss: 1.4961 - val_acc: 0.4768\n",
            "Epoch 160/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.4517 - acc: 0.4951 - val_loss: 1.4904 - val_acc: 0.4772\n",
            "Epoch 161/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4499 - acc: 0.4961 - val_loss: 1.4922 - val_acc: 0.4728\n",
            "Epoch 162/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.4488 - acc: 0.4960 - val_loss: 1.4910 - val_acc: 0.4772\n",
            "Epoch 163/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4473 - acc: 0.4961 - val_loss: 1.4855 - val_acc: 0.4769\n",
            "Epoch 164/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4455 - acc: 0.4964 - val_loss: 1.4883 - val_acc: 0.4755\n",
            "Epoch 165/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4439 - acc: 0.4980 - val_loss: 1.4936 - val_acc: 0.4744\n",
            "Epoch 166/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.4423 - acc: 0.4983 - val_loss: 1.4907 - val_acc: 0.4741\n",
            "Epoch 167/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.4410 - acc: 0.4986 - val_loss: 1.4802 - val_acc: 0.4808\n",
            "Epoch 168/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.4392 - acc: 0.5005 - val_loss: 1.4805 - val_acc: 0.4790\n",
            "Epoch 169/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.4380 - acc: 0.4997 - val_loss: 1.4874 - val_acc: 0.4789\n",
            "Epoch 170/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.4365 - acc: 0.4991 - val_loss: 1.4783 - val_acc: 0.4830\n",
            "Epoch 171/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4349 - acc: 0.5010 - val_loss: 1.4773 - val_acc: 0.4819\n",
            "Epoch 172/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4331 - acc: 0.5018 - val_loss: 1.4766 - val_acc: 0.4809\n",
            "Epoch 173/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4319 - acc: 0.5022 - val_loss: 1.4781 - val_acc: 0.4789\n",
            "Epoch 174/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.4311 - acc: 0.5016 - val_loss: 1.4735 - val_acc: 0.4830\n",
            "Epoch 175/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.4288 - acc: 0.5017 - val_loss: 1.4820 - val_acc: 0.4781\n",
            "Epoch 176/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.4274 - acc: 0.5022 - val_loss: 1.4748 - val_acc: 0.4809\n",
            "Epoch 177/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4257 - acc: 0.5046 - val_loss: 1.4708 - val_acc: 0.4822\n",
            "Epoch 178/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4244 - acc: 0.5032 - val_loss: 1.4691 - val_acc: 0.4825\n",
            "Epoch 179/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.4227 - acc: 0.5042 - val_loss: 1.4713 - val_acc: 0.4834\n",
            "Epoch 180/500\n",
            "50000/50000 [==============================] - 10s 200us/step - loss: 1.4216 - acc: 0.5049 - val_loss: 1.4673 - val_acc: 0.4856\n",
            "Epoch 181/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.4204 - acc: 0.5050 - val_loss: 1.4704 - val_acc: 0.4835\n",
            "Epoch 182/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.4185 - acc: 0.5052 - val_loss: 1.4764 - val_acc: 0.4785\n",
            "Epoch 183/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.4174 - acc: 0.5064 - val_loss: 1.4682 - val_acc: 0.4834\n",
            "Epoch 184/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.4161 - acc: 0.5061 - val_loss: 1.4676 - val_acc: 0.4839\n",
            "Epoch 185/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.4141 - acc: 0.5074 - val_loss: 1.4683 - val_acc: 0.4868\n",
            "Epoch 186/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.4128 - acc: 0.5072 - val_loss: 1.4647 - val_acc: 0.4864\n",
            "Epoch 187/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4115 - acc: 0.5087 - val_loss: 1.4618 - val_acc: 0.4848\n",
            "Epoch 188/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.4099 - acc: 0.5086 - val_loss: 1.4631 - val_acc: 0.4847\n",
            "Epoch 189/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.4086 - acc: 0.5100 - val_loss: 1.4669 - val_acc: 0.4829\n",
            "Epoch 190/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.4069 - acc: 0.5101 - val_loss: 1.4598 - val_acc: 0.4865\n",
            "Epoch 191/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.4060 - acc: 0.5104 - val_loss: 1.4602 - val_acc: 0.4866\n",
            "Epoch 192/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.4041 - acc: 0.5100 - val_loss: 1.4560 - val_acc: 0.4868\n",
            "Epoch 193/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.4029 - acc: 0.5110 - val_loss: 1.4562 - val_acc: 0.4890\n",
            "Epoch 194/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.4017 - acc: 0.5108 - val_loss: 1.4588 - val_acc: 0.4854\n",
            "Epoch 195/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.4001 - acc: 0.5117 - val_loss: 1.4543 - val_acc: 0.4870\n",
            "Epoch 196/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.3983 - acc: 0.5127 - val_loss: 1.4581 - val_acc: 0.4875\n",
            "Epoch 197/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.3971 - acc: 0.5132 - val_loss: 1.4564 - val_acc: 0.4870\n",
            "Epoch 198/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.3956 - acc: 0.5128 - val_loss: 1.4503 - val_acc: 0.4907\n",
            "Epoch 199/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.3944 - acc: 0.5137 - val_loss: 1.4611 - val_acc: 0.4833\n",
            "Epoch 200/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.3930 - acc: 0.5138 - val_loss: 1.4572 - val_acc: 0.4868\n",
            "Epoch 201/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3921 - acc: 0.5150 - val_loss: 1.4495 - val_acc: 0.4882\n",
            "Epoch 202/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3901 - acc: 0.5151 - val_loss: 1.4483 - val_acc: 0.4901\n",
            "Epoch 203/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3887 - acc: 0.5164 - val_loss: 1.4616 - val_acc: 0.4889\n",
            "Epoch 204/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.3876 - acc: 0.5160 - val_loss: 1.4476 - val_acc: 0.4895\n",
            "Epoch 205/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.3860 - acc: 0.5166 - val_loss: 1.4441 - val_acc: 0.4922\n",
            "Epoch 206/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3844 - acc: 0.5177 - val_loss: 1.4431 - val_acc: 0.4943\n",
            "Epoch 207/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.3833 - acc: 0.5171 - val_loss: 1.4452 - val_acc: 0.4887\n",
            "Epoch 208/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.3818 - acc: 0.5183 - val_loss: 1.4413 - val_acc: 0.4931\n",
            "Epoch 209/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3805 - acc: 0.5176 - val_loss: 1.4403 - val_acc: 0.4921\n",
            "Epoch 210/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3793 - acc: 0.5179 - val_loss: 1.4529 - val_acc: 0.4839\n",
            "Epoch 211/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.3783 - acc: 0.5185 - val_loss: 1.4394 - val_acc: 0.4940\n",
            "Epoch 212/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3765 - acc: 0.5193 - val_loss: 1.4426 - val_acc: 0.4915\n",
            "Epoch 213/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3750 - acc: 0.5208 - val_loss: 1.4391 - val_acc: 0.4933\n",
            "Epoch 214/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.3739 - acc: 0.5219 - val_loss: 1.4363 - val_acc: 0.4939\n",
            "Epoch 215/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.3724 - acc: 0.5220 - val_loss: 1.4352 - val_acc: 0.4946\n",
            "Epoch 216/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.3705 - acc: 0.5210 - val_loss: 1.4404 - val_acc: 0.4943\n",
            "Epoch 217/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3694 - acc: 0.5225 - val_loss: 1.4411 - val_acc: 0.4884\n",
            "Epoch 218/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.3680 - acc: 0.5214 - val_loss: 1.4342 - val_acc: 0.4926\n",
            "Epoch 219/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3671 - acc: 0.5224 - val_loss: 1.4391 - val_acc: 0.4918\n",
            "Epoch 220/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.3656 - acc: 0.5241 - val_loss: 1.4475 - val_acc: 0.4922\n",
            "Epoch 221/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.3643 - acc: 0.5246 - val_loss: 1.4484 - val_acc: 0.4914\n",
            "Epoch 222/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3634 - acc: 0.5248 - val_loss: 1.4340 - val_acc: 0.4908\n",
            "Epoch 223/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.3621 - acc: 0.5256 - val_loss: 1.4366 - val_acc: 0.4922\n",
            "Epoch 224/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.3606 - acc: 0.5252 - val_loss: 1.4350 - val_acc: 0.4943\n",
            "Epoch 225/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3594 - acc: 0.5255 - val_loss: 1.4343 - val_acc: 0.4917\n",
            "Epoch 226/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3577 - acc: 0.5251 - val_loss: 1.4328 - val_acc: 0.4951\n",
            "Epoch 227/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.3569 - acc: 0.5261 - val_loss: 1.4348 - val_acc: 0.4935\n",
            "Epoch 228/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3554 - acc: 0.5272 - val_loss: 1.4316 - val_acc: 0.4911\n",
            "Epoch 229/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.3541 - acc: 0.5279 - val_loss: 1.4303 - val_acc: 0.4917\n",
            "Epoch 230/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.3525 - acc: 0.5276 - val_loss: 1.4416 - val_acc: 0.4877\n",
            "Epoch 231/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.3520 - acc: 0.5280 - val_loss: 1.4260 - val_acc: 0.4983\n",
            "Epoch 232/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.3502 - acc: 0.5292 - val_loss: 1.4275 - val_acc: 0.4942\n",
            "Epoch 233/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3489 - acc: 0.5288 - val_loss: 1.4398 - val_acc: 0.4916\n",
            "Epoch 234/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.3475 - acc: 0.5296 - val_loss: 1.4279 - val_acc: 0.4941\n",
            "Epoch 235/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.3460 - acc: 0.5295 - val_loss: 1.4279 - val_acc: 0.4973\n",
            "Epoch 236/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.3450 - acc: 0.5316 - val_loss: 1.4268 - val_acc: 0.4943\n",
            "Epoch 237/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.3439 - acc: 0.5319 - val_loss: 1.4258 - val_acc: 0.4910\n",
            "Epoch 238/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3421 - acc: 0.5323 - val_loss: 1.4208 - val_acc: 0.5015\n",
            "Epoch 239/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3414 - acc: 0.5332 - val_loss: 1.4265 - val_acc: 0.4982\n",
            "Epoch 240/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3400 - acc: 0.5326 - val_loss: 1.4237 - val_acc: 0.4972\n",
            "Epoch 241/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.3385 - acc: 0.5317 - val_loss: 1.4155 - val_acc: 0.4976\n",
            "Epoch 242/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.3377 - acc: 0.5326 - val_loss: 1.4239 - val_acc: 0.4948\n",
            "Epoch 243/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3362 - acc: 0.5338 - val_loss: 1.4283 - val_acc: 0.4968\n",
            "Epoch 244/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3350 - acc: 0.5341 - val_loss: 1.4225 - val_acc: 0.4934\n",
            "Epoch 245/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.3339 - acc: 0.5351 - val_loss: 1.4162 - val_acc: 0.5004\n",
            "Epoch 246/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3319 - acc: 0.5346 - val_loss: 1.4145 - val_acc: 0.4994\n",
            "Epoch 247/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3307 - acc: 0.5367 - val_loss: 1.4143 - val_acc: 0.4998\n",
            "Epoch 248/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3296 - acc: 0.5358 - val_loss: 1.4194 - val_acc: 0.4979\n",
            "Epoch 249/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3292 - acc: 0.5363 - val_loss: 1.4111 - val_acc: 0.5033\n",
            "Epoch 250/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3280 - acc: 0.5361 - val_loss: 1.4083 - val_acc: 0.5029\n",
            "Epoch 251/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3264 - acc: 0.5364 - val_loss: 1.4104 - val_acc: 0.5010\n",
            "Epoch 252/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.3256 - acc: 0.5372 - val_loss: 1.4204 - val_acc: 0.4999\n",
            "Epoch 253/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3237 - acc: 0.5384 - val_loss: 1.4080 - val_acc: 0.5007\n",
            "Epoch 254/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3227 - acc: 0.5391 - val_loss: 1.4182 - val_acc: 0.4998\n",
            "Epoch 255/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3207 - acc: 0.5381 - val_loss: 1.4148 - val_acc: 0.5021\n",
            "Epoch 256/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.3201 - acc: 0.5397 - val_loss: 1.4117 - val_acc: 0.4988\n",
            "Epoch 257/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3190 - acc: 0.5385 - val_loss: 1.4190 - val_acc: 0.4993\n",
            "Epoch 258/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.3177 - acc: 0.5405 - val_loss: 1.4088 - val_acc: 0.4987\n",
            "Epoch 259/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3165 - acc: 0.5402 - val_loss: 1.4170 - val_acc: 0.5001\n",
            "Epoch 260/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3151 - acc: 0.5404 - val_loss: 1.4091 - val_acc: 0.5018\n",
            "Epoch 261/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3146 - acc: 0.5414 - val_loss: 1.4034 - val_acc: 0.5035\n",
            "Epoch 262/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.3131 - acc: 0.5414 - val_loss: 1.4171 - val_acc: 0.4999\n",
            "Epoch 263/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.3114 - acc: 0.5420 - val_loss: 1.4164 - val_acc: 0.4983\n",
            "Epoch 264/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.3107 - acc: 0.5415 - val_loss: 1.4274 - val_acc: 0.4941\n",
            "Epoch 265/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3097 - acc: 0.5417 - val_loss: 1.4070 - val_acc: 0.5037\n",
            "Epoch 266/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3080 - acc: 0.5423 - val_loss: 1.4024 - val_acc: 0.5016\n",
            "Epoch 267/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.3072 - acc: 0.5441 - val_loss: 1.3977 - val_acc: 0.5052\n",
            "Epoch 268/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3064 - acc: 0.5439 - val_loss: 1.4394 - val_acc: 0.4890\n",
            "Epoch 269/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3042 - acc: 0.5451 - val_loss: 1.4108 - val_acc: 0.4983\n",
            "Epoch 270/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3036 - acc: 0.5448 - val_loss: 1.4064 - val_acc: 0.5023\n",
            "Epoch 271/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.3021 - acc: 0.5442 - val_loss: 1.4023 - val_acc: 0.5041\n",
            "Epoch 272/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.3011 - acc: 0.5457 - val_loss: 1.3976 - val_acc: 0.5027\n",
            "Epoch 273/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3001 - acc: 0.5456 - val_loss: 1.3957 - val_acc: 0.5035\n",
            "Epoch 274/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2984 - acc: 0.5462 - val_loss: 1.4016 - val_acc: 0.5027\n",
            "Epoch 275/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2977 - acc: 0.5461 - val_loss: 1.4082 - val_acc: 0.4986\n",
            "Epoch 276/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.2961 - acc: 0.5479 - val_loss: 1.4131 - val_acc: 0.4999\n",
            "Epoch 277/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2951 - acc: 0.5463 - val_loss: 1.4018 - val_acc: 0.5027\n",
            "Epoch 278/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2937 - acc: 0.5481 - val_loss: 1.4143 - val_acc: 0.4997\n",
            "Epoch 279/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2934 - acc: 0.5481 - val_loss: 1.3986 - val_acc: 0.5009\n",
            "Epoch 280/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2922 - acc: 0.5489 - val_loss: 1.4225 - val_acc: 0.4981\n",
            "Epoch 281/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2914 - acc: 0.5486 - val_loss: 1.3985 - val_acc: 0.5053\n",
            "Epoch 282/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2895 - acc: 0.5489 - val_loss: 1.4055 - val_acc: 0.4969\n",
            "Epoch 283/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2885 - acc: 0.5509 - val_loss: 1.4194 - val_acc: 0.4990\n",
            "Epoch 284/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2871 - acc: 0.5498 - val_loss: 1.3896 - val_acc: 0.5074\n",
            "Epoch 285/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2858 - acc: 0.5500 - val_loss: 1.4038 - val_acc: 0.5050\n",
            "Epoch 286/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2852 - acc: 0.5518 - val_loss: 1.4054 - val_acc: 0.5027\n",
            "Epoch 287/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2839 - acc: 0.5513 - val_loss: 1.3890 - val_acc: 0.5042\n",
            "Epoch 288/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2824 - acc: 0.5510 - val_loss: 1.3937 - val_acc: 0.5055\n",
            "Epoch 289/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2820 - acc: 0.5516 - val_loss: 1.3887 - val_acc: 0.5042\n",
            "Epoch 290/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2806 - acc: 0.5520 - val_loss: 1.3908 - val_acc: 0.5053\n",
            "Epoch 291/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2796 - acc: 0.5536 - val_loss: 1.3976 - val_acc: 0.5037\n",
            "Epoch 292/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2778 - acc: 0.5544 - val_loss: 1.4168 - val_acc: 0.4981\n",
            "Epoch 293/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2770 - acc: 0.5545 - val_loss: 1.3879 - val_acc: 0.5038\n",
            "Epoch 294/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2764 - acc: 0.5543 - val_loss: 1.3853 - val_acc: 0.5069\n",
            "Epoch 295/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2734 - acc: 0.5547 - val_loss: 1.4196 - val_acc: 0.5001\n",
            "Epoch 296/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2736 - acc: 0.5559 - val_loss: 1.3942 - val_acc: 0.5059\n",
            "Epoch 297/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2730 - acc: 0.5558 - val_loss: 1.3993 - val_acc: 0.5049\n",
            "Epoch 298/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2709 - acc: 0.5551 - val_loss: 1.4045 - val_acc: 0.5015\n",
            "Epoch 299/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2703 - acc: 0.5559 - val_loss: 1.3948 - val_acc: 0.5034\n",
            "Epoch 300/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2687 - acc: 0.5565 - val_loss: 1.3804 - val_acc: 0.5117\n",
            "Epoch 301/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2677 - acc: 0.5563 - val_loss: 1.3936 - val_acc: 0.5082\n",
            "Epoch 302/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2667 - acc: 0.5575 - val_loss: 1.4341 - val_acc: 0.4919\n",
            "Epoch 303/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2649 - acc: 0.5579 - val_loss: 1.3844 - val_acc: 0.5108\n",
            "Epoch 304/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2642 - acc: 0.5582 - val_loss: 1.3797 - val_acc: 0.5082\n",
            "Epoch 305/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2631 - acc: 0.5589 - val_loss: 1.3823 - val_acc: 0.5078\n",
            "Epoch 306/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2612 - acc: 0.5591 - val_loss: 1.3927 - val_acc: 0.5064\n",
            "Epoch 307/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.2612 - acc: 0.5593 - val_loss: 1.3775 - val_acc: 0.5139\n",
            "Epoch 308/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2607 - acc: 0.5602 - val_loss: 1.3815 - val_acc: 0.5100\n",
            "Epoch 309/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2594 - acc: 0.5593 - val_loss: 1.3781 - val_acc: 0.5119\n",
            "Epoch 310/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.2575 - acc: 0.5620 - val_loss: 1.3897 - val_acc: 0.5087\n",
            "Epoch 311/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2560 - acc: 0.5598 - val_loss: 1.3841 - val_acc: 0.5103\n",
            "Epoch 312/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2564 - acc: 0.5595 - val_loss: 1.3760 - val_acc: 0.5133\n",
            "Epoch 313/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2541 - acc: 0.5608 - val_loss: 1.3878 - val_acc: 0.5079\n",
            "Epoch 314/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2538 - acc: 0.5629 - val_loss: 1.4305 - val_acc: 0.4935\n",
            "Epoch 315/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2533 - acc: 0.5637 - val_loss: 1.3790 - val_acc: 0.5102\n",
            "Epoch 316/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2511 - acc: 0.5631 - val_loss: 1.3781 - val_acc: 0.5130\n",
            "Epoch 317/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2506 - acc: 0.5631 - val_loss: 1.3737 - val_acc: 0.5153\n",
            "Epoch 318/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2494 - acc: 0.5624 - val_loss: 1.4236 - val_acc: 0.4991\n",
            "Epoch 319/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2475 - acc: 0.5651 - val_loss: 1.3795 - val_acc: 0.5072\n",
            "Epoch 320/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.2473 - acc: 0.5632 - val_loss: 1.3818 - val_acc: 0.5078\n",
            "Epoch 321/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.2457 - acc: 0.5647 - val_loss: 1.3808 - val_acc: 0.5087\n",
            "Epoch 322/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.2444 - acc: 0.5655 - val_loss: 1.3940 - val_acc: 0.5094\n",
            "Epoch 323/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2437 - acc: 0.5661 - val_loss: 1.4492 - val_acc: 0.4869\n",
            "Epoch 324/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2434 - acc: 0.5669 - val_loss: 1.3794 - val_acc: 0.5064\n",
            "Epoch 325/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2411 - acc: 0.5659 - val_loss: 1.4135 - val_acc: 0.5006\n",
            "Epoch 326/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2410 - acc: 0.5662 - val_loss: 1.3747 - val_acc: 0.5138\n",
            "Epoch 327/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2393 - acc: 0.5676 - val_loss: 1.3774 - val_acc: 0.5114\n",
            "Epoch 328/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2378 - acc: 0.5668 - val_loss: 1.3776 - val_acc: 0.5121\n",
            "Epoch 329/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2363 - acc: 0.5695 - val_loss: 1.3823 - val_acc: 0.5112\n",
            "Epoch 330/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2356 - acc: 0.5683 - val_loss: 1.3800 - val_acc: 0.5093\n",
            "Epoch 331/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2358 - acc: 0.5678 - val_loss: 1.3914 - val_acc: 0.5074\n",
            "Epoch 332/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2326 - acc: 0.5693 - val_loss: 1.3683 - val_acc: 0.5150\n",
            "Epoch 333/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2336 - acc: 0.5705 - val_loss: 1.3784 - val_acc: 0.5095\n",
            "Epoch 334/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2316 - acc: 0.5698 - val_loss: 1.3926 - val_acc: 0.5068\n",
            "Epoch 335/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.2316 - acc: 0.5702 - val_loss: 1.4075 - val_acc: 0.5040\n",
            "Epoch 336/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2302 - acc: 0.5705 - val_loss: 1.3801 - val_acc: 0.5106\n",
            "Epoch 337/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2282 - acc: 0.5704 - val_loss: 1.3654 - val_acc: 0.5150\n",
            "Epoch 338/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2271 - acc: 0.5710 - val_loss: 1.4244 - val_acc: 0.4972\n",
            "Epoch 339/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2267 - acc: 0.5724 - val_loss: 1.3820 - val_acc: 0.5127\n",
            "Epoch 340/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2250 - acc: 0.5720 - val_loss: 1.3673 - val_acc: 0.5186\n",
            "Epoch 341/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2231 - acc: 0.5735 - val_loss: 1.3823 - val_acc: 0.5093\n",
            "Epoch 342/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2231 - acc: 0.5734 - val_loss: 1.3758 - val_acc: 0.5118\n",
            "Epoch 343/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2230 - acc: 0.5721 - val_loss: 1.3616 - val_acc: 0.5186\n",
            "Epoch 344/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2211 - acc: 0.5746 - val_loss: 1.3817 - val_acc: 0.5075\n",
            "Epoch 345/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.2203 - acc: 0.5733 - val_loss: 1.3814 - val_acc: 0.5111\n",
            "Epoch 346/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2185 - acc: 0.5747 - val_loss: 1.4028 - val_acc: 0.5060\n",
            "Epoch 347/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2183 - acc: 0.5748 - val_loss: 1.3609 - val_acc: 0.5222\n",
            "Epoch 348/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.2162 - acc: 0.5768 - val_loss: 1.3738 - val_acc: 0.5128\n",
            "Epoch 349/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2162 - acc: 0.5754 - val_loss: 1.4084 - val_acc: 0.5003\n",
            "Epoch 350/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.2149 - acc: 0.5762 - val_loss: 1.3676 - val_acc: 0.5150\n",
            "Epoch 351/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2130 - acc: 0.5777 - val_loss: 1.3990 - val_acc: 0.5063\n",
            "Epoch 352/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2125 - acc: 0.5766 - val_loss: 1.3923 - val_acc: 0.5060\n",
            "Epoch 353/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2120 - acc: 0.5773 - val_loss: 1.3642 - val_acc: 0.5154\n",
            "Epoch 354/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2099 - acc: 0.5775 - val_loss: 1.3630 - val_acc: 0.5185\n",
            "Epoch 355/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.2082 - acc: 0.5786 - val_loss: 1.3603 - val_acc: 0.5198\n",
            "Epoch 356/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.2080 - acc: 0.5788 - val_loss: 1.3625 - val_acc: 0.5173\n",
            "Epoch 357/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.2074 - acc: 0.5804 - val_loss: 1.3659 - val_acc: 0.5148\n",
            "Epoch 358/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2064 - acc: 0.5786 - val_loss: 1.3745 - val_acc: 0.5146\n",
            "Epoch 359/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.2059 - acc: 0.5805 - val_loss: 1.3727 - val_acc: 0.5151\n",
            "Epoch 360/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.2036 - acc: 0.5800 - val_loss: 1.3737 - val_acc: 0.5139\n",
            "Epoch 361/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2028 - acc: 0.5801 - val_loss: 1.3717 - val_acc: 0.5102\n",
            "Epoch 362/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2019 - acc: 0.5810 - val_loss: 1.3670 - val_acc: 0.5190\n",
            "Epoch 363/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2006 - acc: 0.5817 - val_loss: 1.3804 - val_acc: 0.5102\n",
            "Epoch 364/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2004 - acc: 0.5814 - val_loss: 1.3609 - val_acc: 0.5137\n",
            "Epoch 365/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1989 - acc: 0.5833 - val_loss: 1.3766 - val_acc: 0.5132\n",
            "Epoch 366/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1987 - acc: 0.5822 - val_loss: 1.3877 - val_acc: 0.5125\n",
            "Epoch 367/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1961 - acc: 0.5819 - val_loss: 1.3546 - val_acc: 0.5182\n",
            "Epoch 368/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1968 - acc: 0.5834 - val_loss: 1.3612 - val_acc: 0.5131\n",
            "Epoch 369/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1945 - acc: 0.5827 - val_loss: 1.3660 - val_acc: 0.5161\n",
            "Epoch 370/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1921 - acc: 0.5854 - val_loss: 1.3547 - val_acc: 0.5173\n",
            "Epoch 371/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1915 - acc: 0.5850 - val_loss: 1.3587 - val_acc: 0.5179\n",
            "Epoch 372/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.1909 - acc: 0.5836 - val_loss: 1.3651 - val_acc: 0.5158\n",
            "Epoch 373/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1904 - acc: 0.5847 - val_loss: 1.3528 - val_acc: 0.5194\n",
            "Epoch 374/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.1903 - acc: 0.5855 - val_loss: 1.3519 - val_acc: 0.5211\n",
            "Epoch 375/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.1888 - acc: 0.5856 - val_loss: 1.3903 - val_acc: 0.5069\n",
            "Epoch 376/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.1867 - acc: 0.5876 - val_loss: 1.3799 - val_acc: 0.5143\n",
            "Epoch 377/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1860 - acc: 0.5858 - val_loss: 1.3521 - val_acc: 0.5190\n",
            "Epoch 378/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1853 - acc: 0.5872 - val_loss: 1.3690 - val_acc: 0.5113\n",
            "Epoch 379/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.1847 - acc: 0.5877 - val_loss: 1.3586 - val_acc: 0.5167\n",
            "Epoch 380/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1846 - acc: 0.5881 - val_loss: 1.3587 - val_acc: 0.5188\n",
            "Epoch 381/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1815 - acc: 0.5878 - val_loss: 1.3646 - val_acc: 0.5140\n",
            "Epoch 382/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1817 - acc: 0.5868 - val_loss: 1.3656 - val_acc: 0.5173\n",
            "Epoch 383/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1795 - acc: 0.5906 - val_loss: 1.3756 - val_acc: 0.5162\n",
            "Epoch 384/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.1794 - acc: 0.5891 - val_loss: 1.3506 - val_acc: 0.5230\n",
            "Epoch 385/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1789 - acc: 0.5901 - val_loss: 1.3482 - val_acc: 0.5223\n",
            "Epoch 386/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.1783 - acc: 0.5898 - val_loss: 1.3717 - val_acc: 0.5168\n",
            "Epoch 387/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1752 - acc: 0.5915 - val_loss: 1.3497 - val_acc: 0.5183\n",
            "Epoch 388/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1758 - acc: 0.5899 - val_loss: 1.3670 - val_acc: 0.5196\n",
            "Epoch 389/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1735 - acc: 0.5914 - val_loss: 1.3636 - val_acc: 0.5182\n",
            "Epoch 390/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.1729 - acc: 0.5905 - val_loss: 1.3645 - val_acc: 0.5162\n",
            "Epoch 391/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.1711 - acc: 0.5911 - val_loss: 1.3910 - val_acc: 0.5073\n",
            "Epoch 392/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1714 - acc: 0.5915 - val_loss: 1.3573 - val_acc: 0.5181\n",
            "Epoch 393/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1704 - acc: 0.5914 - val_loss: 1.3589 - val_acc: 0.5229\n",
            "Epoch 394/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.1695 - acc: 0.5927 - val_loss: 1.3605 - val_acc: 0.5185\n",
            "Epoch 395/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.1674 - acc: 0.5941 - val_loss: 1.3521 - val_acc: 0.5208\n",
            "Epoch 396/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1671 - acc: 0.5939 - val_loss: 1.3526 - val_acc: 0.5181\n",
            "Epoch 397/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.1661 - acc: 0.5939 - val_loss: 1.3482 - val_acc: 0.5237\n",
            "Epoch 398/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1636 - acc: 0.5949 - val_loss: 1.3599 - val_acc: 0.5154\n",
            "Epoch 399/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1628 - acc: 0.5951 - val_loss: 1.3433 - val_acc: 0.5244\n",
            "Epoch 400/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.1634 - acc: 0.5951 - val_loss: 1.3551 - val_acc: 0.5188\n",
            "Epoch 401/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.1622 - acc: 0.5959 - val_loss: 1.3481 - val_acc: 0.5216\n",
            "Epoch 402/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.1598 - acc: 0.5963 - val_loss: 1.3781 - val_acc: 0.5112\n",
            "Epoch 403/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.1605 - acc: 0.5958 - val_loss: 1.3702 - val_acc: 0.5183\n",
            "Epoch 404/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1599 - acc: 0.5962 - val_loss: 1.3420 - val_acc: 0.5236\n",
            "Epoch 405/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1592 - acc: 0.5959 - val_loss: 1.4058 - val_acc: 0.5013\n",
            "Epoch 406/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1568 - acc: 0.5965 - val_loss: 1.3471 - val_acc: 0.5228\n",
            "Epoch 407/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1570 - acc: 0.5968 - val_loss: 1.3482 - val_acc: 0.5208\n",
            "Epoch 408/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.1549 - acc: 0.5960 - val_loss: 1.3625 - val_acc: 0.5201\n",
            "Epoch 409/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.1562 - acc: 0.5963 - val_loss: 1.3768 - val_acc: 0.5117\n",
            "Epoch 410/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1538 - acc: 0.5994 - val_loss: 1.3447 - val_acc: 0.5222\n",
            "Epoch 411/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1510 - acc: 0.5988 - val_loss: 1.3606 - val_acc: 0.5208\n",
            "Epoch 412/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.1503 - acc: 0.5994 - val_loss: 1.4063 - val_acc: 0.5094\n",
            "Epoch 413/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1491 - acc: 0.6002 - val_loss: 1.3873 - val_acc: 0.5089\n",
            "Epoch 414/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1482 - acc: 0.5999 - val_loss: 1.3462 - val_acc: 0.5209\n",
            "Epoch 415/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1467 - acc: 0.6009 - val_loss: 1.3759 - val_acc: 0.5038\n",
            "Epoch 416/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1468 - acc: 0.6011 - val_loss: 1.4411 - val_acc: 0.4972\n",
            "Epoch 417/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1459 - acc: 0.6014 - val_loss: 1.3529 - val_acc: 0.5183\n",
            "Epoch 418/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1440 - acc: 0.6011 - val_loss: 1.3537 - val_acc: 0.5196\n",
            "Epoch 419/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.1418 - acc: 0.6020 - val_loss: 1.3850 - val_acc: 0.5055\n",
            "Epoch 420/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1422 - acc: 0.6010 - val_loss: 1.4055 - val_acc: 0.5007\n",
            "Epoch 421/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1406 - acc: 0.6022 - val_loss: 1.3606 - val_acc: 0.5221\n",
            "Epoch 422/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1424 - acc: 0.6022 - val_loss: 1.3612 - val_acc: 0.5207\n",
            "Epoch 423/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.1420 - acc: 0.6020 - val_loss: 1.3390 - val_acc: 0.5257\n",
            "Epoch 424/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1385 - acc: 0.6035 - val_loss: 1.3489 - val_acc: 0.5203\n",
            "Epoch 425/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.1368 - acc: 0.6033 - val_loss: 1.3650 - val_acc: 0.5179\n",
            "Epoch 426/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1369 - acc: 0.6052 - val_loss: 1.3895 - val_acc: 0.5093\n",
            "Epoch 427/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1359 - acc: 0.6050 - val_loss: 1.3433 - val_acc: 0.5231\n",
            "Epoch 428/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1351 - acc: 0.6044 - val_loss: 1.3679 - val_acc: 0.5182\n",
            "Epoch 429/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 1.1322 - acc: 0.6050 - val_loss: 1.3525 - val_acc: 0.5227\n",
            "Epoch 430/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.1320 - acc: 0.6050 - val_loss: 1.3628 - val_acc: 0.5184\n",
            "Epoch 431/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.1312 - acc: 0.6073 - val_loss: 1.3735 - val_acc: 0.5181\n",
            "Epoch 432/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.1308 - acc: 0.6064 - val_loss: 1.3710 - val_acc: 0.5198\n",
            "Epoch 433/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1293 - acc: 0.6075 - val_loss: 1.3486 - val_acc: 0.5247\n",
            "Epoch 434/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.1306 - acc: 0.6059 - val_loss: 1.3480 - val_acc: 0.5240\n",
            "Epoch 435/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.1264 - acc: 0.6076 - val_loss: 1.3851 - val_acc: 0.5128\n",
            "Epoch 436/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1277 - acc: 0.6077 - val_loss: 1.3453 - val_acc: 0.5261\n",
            "Epoch 437/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.1235 - acc: 0.6091 - val_loss: 1.3580 - val_acc: 0.5178\n",
            "Epoch 438/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.1255 - acc: 0.6095 - val_loss: 1.3538 - val_acc: 0.5227\n",
            "Epoch 439/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.1247 - acc: 0.6083 - val_loss: 1.3510 - val_acc: 0.5172\n",
            "Epoch 440/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.1225 - acc: 0.6093 - val_loss: 1.3582 - val_acc: 0.5235\n",
            "Epoch 441/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1230 - acc: 0.6094 - val_loss: 1.3515 - val_acc: 0.5186\n",
            "Epoch 442/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.1212 - acc: 0.6087 - val_loss: 1.3511 - val_acc: 0.5206\n",
            "Epoch 443/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1202 - acc: 0.6092 - val_loss: 1.3790 - val_acc: 0.5155\n",
            "Epoch 444/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1195 - acc: 0.6117 - val_loss: 1.4092 - val_acc: 0.5100\n",
            "Epoch 445/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.1193 - acc: 0.6101 - val_loss: 1.3685 - val_acc: 0.5105\n",
            "Epoch 446/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.1184 - acc: 0.6099 - val_loss: 1.3408 - val_acc: 0.5246\n",
            "Epoch 447/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.1176 - acc: 0.6098 - val_loss: 1.3550 - val_acc: 0.5205\n",
            "Epoch 448/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1133 - acc: 0.6123 - val_loss: 1.3482 - val_acc: 0.5261\n",
            "Epoch 449/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1150 - acc: 0.6118 - val_loss: 1.3489 - val_acc: 0.5216\n",
            "Epoch 450/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1127 - acc: 0.6115 - val_loss: 1.3333 - val_acc: 0.5265\n",
            "Epoch 451/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1108 - acc: 0.6144 - val_loss: 1.3376 - val_acc: 0.5223\n",
            "Epoch 452/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1100 - acc: 0.6125 - val_loss: 1.3740 - val_acc: 0.5119\n",
            "Epoch 453/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1108 - acc: 0.6120 - val_loss: 1.3551 - val_acc: 0.5244\n",
            "Epoch 454/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.1092 - acc: 0.6132 - val_loss: 1.3802 - val_acc: 0.5101\n",
            "Epoch 455/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1072 - acc: 0.6137 - val_loss: 1.3376 - val_acc: 0.5254\n",
            "Epoch 456/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.1068 - acc: 0.6147 - val_loss: 1.4920 - val_acc: 0.4865\n",
            "Epoch 457/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.1061 - acc: 0.6142 - val_loss: 1.3618 - val_acc: 0.5129\n",
            "Epoch 458/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1042 - acc: 0.6157 - val_loss: 1.3583 - val_acc: 0.5209\n",
            "Epoch 459/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.1066 - acc: 0.6129 - val_loss: 1.3465 - val_acc: 0.5227\n",
            "Epoch 460/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.1038 - acc: 0.6148 - val_loss: 1.3514 - val_acc: 0.5185\n",
            "Epoch 461/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1012 - acc: 0.6169 - val_loss: 1.3717 - val_acc: 0.5123\n",
            "Epoch 462/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1002 - acc: 0.6164 - val_loss: 1.4299 - val_acc: 0.5037\n",
            "Epoch 463/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.1001 - acc: 0.6162 - val_loss: 1.3697 - val_acc: 0.5198\n",
            "Epoch 464/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0993 - acc: 0.6167 - val_loss: 1.3683 - val_acc: 0.5141\n",
            "Epoch 465/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.0988 - acc: 0.6188 - val_loss: 1.3447 - val_acc: 0.5251\n",
            "Epoch 466/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.0981 - acc: 0.6179 - val_loss: 1.3470 - val_acc: 0.5231\n",
            "Epoch 467/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.0970 - acc: 0.6182 - val_loss: 1.3402 - val_acc: 0.5270\n",
            "Epoch 468/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.0935 - acc: 0.6201 - val_loss: 1.3747 - val_acc: 0.5148\n",
            "Epoch 469/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.0949 - acc: 0.6189 - val_loss: 1.3404 - val_acc: 0.5233\n",
            "Epoch 470/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.0934 - acc: 0.6190 - val_loss: 1.3455 - val_acc: 0.5206\n",
            "Epoch 471/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.0937 - acc: 0.6190 - val_loss: 1.3420 - val_acc: 0.5189\n",
            "Epoch 472/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.0913 - acc: 0.6197 - val_loss: 1.3570 - val_acc: 0.5242\n",
            "Epoch 473/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.0905 - acc: 0.6214 - val_loss: 1.3376 - val_acc: 0.5206\n",
            "Epoch 474/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.0912 - acc: 0.6198 - val_loss: 1.3361 - val_acc: 0.5260\n",
            "Epoch 475/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.0902 - acc: 0.6194 - val_loss: 1.3335 - val_acc: 0.5260\n",
            "Epoch 476/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.0878 - acc: 0.6191 - val_loss: 1.3864 - val_acc: 0.5100\n",
            "Epoch 477/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.0878 - acc: 0.6209 - val_loss: 1.3878 - val_acc: 0.5175\n",
            "Epoch 478/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.0845 - acc: 0.6212 - val_loss: 1.3450 - val_acc: 0.5255\n",
            "Epoch 479/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.0876 - acc: 0.6201 - val_loss: 1.3792 - val_acc: 0.5163\n",
            "Epoch 480/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0814 - acc: 0.6241 - val_loss: 1.4231 - val_acc: 0.5060\n",
            "Epoch 481/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.0843 - acc: 0.6223 - val_loss: 1.3687 - val_acc: 0.5178\n",
            "Epoch 482/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.0814 - acc: 0.6252 - val_loss: 1.3517 - val_acc: 0.5214\n",
            "Epoch 483/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.0821 - acc: 0.6228 - val_loss: 1.3901 - val_acc: 0.5101\n",
            "Epoch 484/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.0804 - acc: 0.6227 - val_loss: 1.3597 - val_acc: 0.5187\n",
            "Epoch 485/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.0810 - acc: 0.6240 - val_loss: 1.3400 - val_acc: 0.5269\n",
            "Epoch 486/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0776 - acc: 0.6264 - val_loss: 1.3700 - val_acc: 0.5131\n",
            "Epoch 487/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0766 - acc: 0.6267 - val_loss: 1.4188 - val_acc: 0.5080\n",
            "Epoch 488/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.0791 - acc: 0.6226 - val_loss: 1.3549 - val_acc: 0.5223\n",
            "Epoch 489/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.0762 - acc: 0.6251 - val_loss: 1.3820 - val_acc: 0.5149\n",
            "Epoch 490/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.0744 - acc: 0.6260 - val_loss: 1.3775 - val_acc: 0.5140\n",
            "Epoch 491/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.0746 - acc: 0.6264 - val_loss: 1.3415 - val_acc: 0.5242\n",
            "Epoch 492/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.0749 - acc: 0.6250 - val_loss: 1.3427 - val_acc: 0.5288\n",
            "Epoch 493/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.0723 - acc: 0.6275 - val_loss: 1.3926 - val_acc: 0.5089\n",
            "Epoch 494/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0711 - acc: 0.6270 - val_loss: 1.3400 - val_acc: 0.5281\n",
            "Epoch 495/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.0702 - acc: 0.6267 - val_loss: 1.3554 - val_acc: 0.5203\n",
            "Epoch 496/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.0699 - acc: 0.6277 - val_loss: 1.3836 - val_acc: 0.5150\n",
            "Epoch 497/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.0679 - acc: 0.6276 - val_loss: 1.3728 - val_acc: 0.5191\n",
            "Epoch 498/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 1.0690 - acc: 0.6265 - val_loss: 1.3381 - val_acc: 0.5294\n",
            "Epoch 499/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.0697 - acc: 0.6273 - val_loss: 1.3683 - val_acc: 0.5173\n",
            "Epoch 500/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.0640 - acc: 0.6287 - val_loss: 1.4027 - val_acc: 0.5096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb08b6509e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCPez2I4rnYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c9ea1a9c-843b-425f-9f6a-93888b570718"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 以視覺畫方式檢視訓練過程\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nksOKk-7uYwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}